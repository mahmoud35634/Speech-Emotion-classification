

# Speech Emotion Detection
## Overview
Emotion detection from speech is a critical component in human-computer interaction, enhancing user experience by making systems more responsive to human emotions. This project aims to develop a model that can accurately detect emotions from speech recordings using machine learning algorithms.

## Features
<ol>
- Data Preprocessing: Cleaning and normalizing audio data, extracting features such as MFCCs (Mel Frequency Cepstral Coefficients), and augmenting the dataset.
- Exploratory Data Analysis (EDA): Visualizing audio features and understanding the distribution of emotions.
- Model Development: Implementing various machine learning and deep learning algorithms to find the best predictive model.
- Model Evaluation: Assessing model performance using metrics such as accuracy, precision, recall, and F1 score.
- Deployment: Integrating the model into an application for real-time emotion detection.</ol>

## Data
The dataset used for this project includes audio recordings of speech labeled with different emotions such as happiness, sadness, anger, fear, and neutral. The data has been sourced from publicly available emotional speech databases.

you can get the data from this link 

https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess


# Video URL 
https://drive.google.com/file/d/1kNnhdf4V_dyDNjhNopcLmcbxTqqlRLJx/view?usp=drive_link
